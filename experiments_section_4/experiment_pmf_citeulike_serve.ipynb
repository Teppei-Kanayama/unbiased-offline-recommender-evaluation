{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment-pmf-citeulike-serve.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ylongqi/unbiased-offline-recommender-evaluation/blob/master/experiments_section_4/experiment_pmf_citeulike_serve.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Ci8jdAKI94bm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install framework and download datasets"
      ]
    },
    {
      "metadata": {
        "id": "nj_-Pf1VWp_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d98a5e58-6c00-42b0-f09e-65e1287ab1dc"
      },
      "cell_type": "code",
      "source": [
        "!pip install openrec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openrec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/e5/0c4688f97a3e22c0ecee1ac295aa5ebf46ef49d3e9fe14bb5a8e01d838e2/openrec-0.2.3.tar.gz (46kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.15.0 in /usr/local/lib/python2.7/dist-packages (from openrec) (4.26.0)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python2.7/dist-packages (from openrec) (1.14.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from openrec) (1.1.0)\n",
            "Building wheels for collected packages: openrec\n",
            "  Running setup.py bdist_wheel for openrec ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/af/f0/59/fdb60eccb7921f144d67a3b6a1098453e85424b75329b9607d\n",
            "Successfully built openrec\n",
            "Installing collected packages: openrec\n",
            "Successfully installed openrec-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nN1Mi8u_W1ox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf *\n",
        "\n",
        "!wget https://s3.amazonaws.com/cornell-tech-sdl-rec-bias/dataset/citeulike/rsrf_user_data_train.npy\n",
        "!wget https://s3.amazonaws.com/cornell-tech-sdl-rec-bias/dataset/citeulike/rsrf_user_data_val.npy\n",
        "!wget https://s3.amazonaws.com/cornell-tech-sdl-rec-bias/dataset/citeulike/rsrf_user_data_test.npy\n",
        "\n",
        "!wget https://s3.amazonaws.com/cornell-tech-sdl-rec-bias/best-models/pmf-citeulike/pmf-citeulike-all.data-00000-of-00001\n",
        "!wget https://s3.amazonaws.com/cornell-tech-sdl-rec-bias/best-models/pmf-citeulike/pmf-citeulike-all.index\n",
        "!wget https://s3.amazonaws.com/cornell-tech-sdl-rec-bias/best-models/pmf-citeulike/pmf-citeulike-all.meta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abglfI66Hy2S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "from __future__ import division\n",
        "\n",
        "from openrec.legacy import ImplicitModelTrainer\n",
        "from openrec.legacy.utils import ImplicitDataset\n",
        "from openrec.legacy.utils.evaluators import ImplicitEvalManager\n",
        "from openrec.legacy.recommenders import PMF\n",
        "from openrec.legacy.utils.evaluators import AUC, Recall, NDCG\n",
        "from openrec.legacy.utils.samplers import PointwiseSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7Hj1DzI-pcB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function Definition"
      ]
    },
    {
      "metadata": {
        "id": "vvB7zW54Jd4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function that calculates auc, recall and dcg of the evaulation result\n",
        "def eq12_test(infilename, trainfilename, mimic_uniform_sampling=False, gamma=0.2, K=10):\n",
        "    infile = open(infilename, 'rb')\n",
        "    P = pickle.load(infile)\n",
        "    infile.close()\n",
        "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
        "    _NUM_POSs = dict()\n",
        "    \n",
        "    for theuser in P[\"users\"]:\n",
        "        _NUM_POSs[theuser] = len(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
        "        P[\"user_items\"][theuser] = list(P[\"user_items\"][theuser])[-300:]\n",
        "        P[\"results\"][theuser] = list(P[\"results\"][theuser])[-300:]\n",
        "    \n",
        "    Zui = dict()\n",
        "    Ni = dict()\n",
        "    # fill in dictionary Ni\n",
        "    trainset = np.load(trainfilename)\n",
        "    for i in trainset['item_id']:\n",
        "        if i in Ni:\n",
        "            Ni[i] += 1\n",
        "        else:\n",
        "            Ni[i] = 1\n",
        "    del trainset\n",
        "    \n",
        "    # count #users with non-zero item frequencies\n",
        "    nonzero_user_count = 0\n",
        "    for theuser in P[\"users\"]:\n",
        "        pos_items = P[\"user_items\"][theuser][0 - _NUM_POSs[theuser]:]\n",
        "        for pos_item in pos_items:\n",
        "            if pos_item in Ni:\n",
        "                nonzero_user_count += 1\n",
        "                break\n",
        "                \n",
        "    # fill in dictionary Zui\n",
        "    for theuser in P[\"users\"]:\n",
        "        all_scores = np.array(P[\"results\"][theuser])\n",
        "        pos_items = P[\"user_items\"][theuser][0 - _NUM_POSs[theuser]:]\n",
        "        pos_scores = P[\"results\"][theuser][0 - _NUM_POSs[theuser]:]\n",
        "        for i, pos_item in enumerate(pos_items):\n",
        "            pos_score = pos_scores[i]\n",
        "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
        "            \n",
        "    # calculate per-user scores\n",
        "    sum_user_auc = 0.0\n",
        "    sum_user_dcg = 0.0\n",
        "    sum_user_recall = 0.0\n",
        "    sum_user_dcg_all = 0.0\n",
        "    for theuser in P[\"users\"]:\n",
        "        numerator_auc = 0.0\n",
        "        numerator_dcg_all = 0.0\n",
        "        numerator_recall = 0.0\n",
        "        numerator_dcg = 0.0\n",
        "        denominator = 0.0\n",
        "        for theitem in P[\"user_items\"][theuser][0 - _NUM_POSs[theuser]:]:\n",
        "            if theitem not in Ni:\n",
        "                continue\n",
        "            pui = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
        "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) / pui\n",
        "            numerator_dcg_all += (1 / np.log2(Zui[(theuser, theitem)] + 2)) / pui\n",
        "            if Zui[(theuser, theitem)] < K:\n",
        "                numerator_dcg += (1 / np.log2(Zui[(theuser, theitem)] + 2)) / pui\n",
        "                numerator_recall += 1.0 / pui\n",
        "            denominator += 1 / pui\n",
        "        if denominator > 0:\n",
        "            sum_user_auc += numerator_auc / denominator\n",
        "            sum_user_dcg += numerator_dcg / denominator\n",
        "            sum_user_recall += numerator_recall / denominator\n",
        "            sum_user_dcg_all += numerator_dcg_all / denominator\n",
        "    \n",
        "    return {\n",
        "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
        "        \"dcg\"       : sum_user_dcg / nonzero_user_count,\n",
        "        \"recall\"    : sum_user_recall / nonzero_user_count,\n",
        "        \"dcg@all\"   : sum_user_dcg_all / nonzero_user_count\n",
        "    }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lJ4Bo3M7-4Oq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Serving"
      ]
    },
    {
      "metadata": {
        "id": "LTZx-S3ZH5GH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training/val/test data\n",
        "\n",
        "raw_data = dict()\n",
        "raw_data['train_data'] = np.load(\"rsrf_user_data_train.npy\")\n",
        "raw_data['val_data'] = np.load(\"rsrf_user_data_val.npy\")\n",
        "raw_data['test_data'] = np.load(\"rsrf_user_data_test.npy\")\n",
        "raw_data['max_user'] = 5551\n",
        "raw_data['max_item'] = 16980\n",
        "\n",
        "batch_size = 8000\n",
        "test_batch_size = 1000\n",
        "display_itr = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtqelx87Ivki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
        "val_dataset = ImplicitDataset(raw_data['val_data'], raw_data['max_user'], raw_data['max_item'], name='Val')\n",
        "test_dataset = ImplicitDataset(raw_data['test_data'], raw_data['max_user'], raw_data['max_item'], name='Test')\n",
        "\n",
        "# declare model and sampler\n",
        "model = PMF(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(), \n",
        "            dim_embed=50, opt='Adam', sess_config=None, l2_reg=0.0)\n",
        "sampler = PointwiseSampler(batch_size=batch_size, dataset=train_dataset, pos_ratio=0.2, num_process=5)\n",
        "\n",
        "# declare model trainer and evaluation metrics\n",
        "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size, \n",
        "    train_dataset=train_dataset, model=model, sampler=sampler, \n",
        "    eval_save_prefix=\"./0.0-pmf-citeulike\")\n",
        "auc_evaluator = AUC()\n",
        "recall_evaluator = Recall(recall_at=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
        "dcg_evaluator = NDCG(ndcg_at=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
        "\n",
        "\n",
        "model.load(\"pmf-citeulike-all\")     #load model\n",
        "\n",
        "model_trainer._eval_manager = ImplicitEvalManager(evaluators=[auc_evaluator, recall_evaluator, dcg_evaluator])\n",
        "model_trainer._num_negatives = 200\n",
        "model_trainer._exclude_positives([train_dataset, val_dataset, test_dataset])\n",
        "model_trainer._sample_negatives(seed=10)\n",
        "model_trainer._eval_save_prefix = \"pmf-citeulike-test\"\n",
        "model_trainer._evaluate_partial(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keio774maffR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evalution test set under different gamma values"
      ]
    },
    {
      "metadata": {
        "id": "hNlz9U79aYsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "905dee32-e36e-4543-a14c-0b37e8308016"
      },
      "cell_type": "code",
      "source": [
        "# Evaluation on test set\n",
        "\n",
        "test_eval_file = \"pmf-citeulike-test_evaluate_partial.pickle\"\n",
        "trainfilename = \"rsrf_user_data_train.npy\"\n",
        "\n",
        "for gamma in [-1.0, 1.55, 1.69, 1.89]:\n",
        "      print(test_eval_file +  \" with gamma @\" + str(gamma) + \" :\")\n",
        "      print(eq12_test(test_eval_file, trainfilename, False, gamma, 1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pmf-citeulike-test_evaluate_partial.pickle with gamma @-1.0 :\n",
            "{'dcg': 0.1705733547559378, 'auc': 0.9352016691878766, 'dcg@all': 0.4700232822328804, 'recall': 0.1705733547559378}\n",
            "pmf-citeulike-test_evaluate_partial.pickle with gamma @1.55 :\n",
            "{'dcg': 0.0999129124771798, 'auc': 0.9110870669662351, 'dcg@all': 0.3993879306455869, 'recall': 0.0999129124771798}\n",
            "pmf-citeulike-test_evaluate_partial.pickle with gamma @1.69 :\n",
            "{'dcg': 0.09793321878764621, 'auc': 0.910129043348133, 'dcg@all': 0.3971521688853667, 'recall': 0.09793321878764621}\n",
            "pmf-citeulike-test_evaluate_partial.pickle with gamma @1.89 :\n",
            "{'dcg': 0.09532463864051804, 'auc': 0.9088317026258013, 'dcg@all': 0.394176410182987, 'recall': 0.09532463864051804}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UUSOe6pujZvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}